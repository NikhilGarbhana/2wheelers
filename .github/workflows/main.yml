name: KineticGreen Web Scraper

on:
  workflow_dispatch:  # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3.1.3

    - name: Install Chrome and ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip curl
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get install -f -y
        CHROME_VERSION=$(google-chrome --version | grep -oP '\d+' | head -1)
        DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION")
        wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
        unzip /tmp/chromedriver.zip -d /usr/local/bin/
        chmod +x /usr/local/bin/chromedriver

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Run the scraping script
      run: python3 test.py

    - name: Upload output CSV
      uses: ./.github/actions/upload-artifact
      with:
        name: kineticgreen-csv
        path: kineticgreen.csv
